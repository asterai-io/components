package asterai:llm@1.0.0;

interface llm {
  /// Sends a prompt to an LLM and returns the response.
  /// Model format: "provider/model"
  /// The supported providers are:
  ///   openai, anthropic, mistral, and groq.
  /// Example model strings:
  ///   - openai/gpt-5-mini
  ///   - anthropic/claude-opus-4-6
  ///   - mistral/mistral-large-latest
  ///   - groq/llama-3.1-8b-instant
  /// API keys are read from environment variables: OPENAI_KEY, ANTHROPIC_KEY, etc.
  prompt: func(prompt: string, model: string) -> string;
}

world component {
  import asterai:host/api@1.0.0;

  export llm;
}
